{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3f4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class GaussianFeatures(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Uniformly spaced Gaussian features for one-dimensional input\"\"\"\n",
    "    \n",
    "    def __init__(self, N, width_factor=2.0):\n",
    "        self.N = N\n",
    "        self.width_factor = width_factor\n",
    "    \n",
    "    # this is a static function, similar to C++\n",
    "    # does not binded with a class instance\n",
    "    @staticmethod\n",
    "    def _gauss_basis(x, y, width, axis=None):\n",
    "        arg = (x - y) / width\n",
    "        return np.exp(-0.5 * np.sum(arg ** 2, axis))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # create N centers spread along the data range\n",
    "        self.centers_ = np.linspace(X.min(), X.max(), self.N)\n",
    "        self.width_ = self.width_factor * (self.centers_[1] - self.centers_[0])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._gauss_basis(X[:, :, np.newaxis], self.centers_,\n",
    "                                 self.width_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db711d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# these two files are large, and it may take a while to read...\n",
    "counts = pd.read_csv('data/FremontBridge.csv', index_col='Date', parse_dates=True)\n",
    "weather = pd.read_csv('data/BicycleWeather.csv', index_col='DATE', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1535e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61296\n",
      "1340\n",
      "                     Fremont Bridge East Sidewalk  \\\n",
      "Date                                                \n",
      "2019-01-01 00:00:00                           0.0   \n",
      "2019-01-01 01:00:00                           2.0   \n",
      "2019-01-01 02:00:00                           1.0   \n",
      "2019-01-01 03:00:00                           1.0   \n",
      "2019-01-01 04:00:00                           2.0   \n",
      "\n",
      "                     Fremont Bridge West Sidewalk  \n",
      "Date                                               \n",
      "2019-01-01 00:00:00                           9.0  \n",
      "2019-01-01 01:00:00                          22.0  \n",
      "2019-01-01 02:00:00                          11.0  \n",
      "2019-01-01 03:00:00                           2.0  \n",
      "2019-01-01 04:00:00                           1.0  \n",
      "                      STATION                                STATION_NAME  \\\n",
      "DATE                                                                        \n",
      "2012-01-01  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US   \n",
      "2012-01-02  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US   \n",
      "2012-01-03  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US   \n",
      "2012-01-04  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US   \n",
      "2012-01-05  GHCND:USW00024233  SEATTLE TACOMA INTERNATIONAL AIRPORT WA US   \n",
      "\n",
      "            PRCP  SNWD  SNOW  TMAX  TMIN  AWND  WDF2  WDF5  ...  WT17  WT05  \\\n",
      "DATE                                                        ...               \n",
      "2012-01-01     0     0     0   128    50    47   100    90  ... -9999 -9999   \n",
      "2012-01-02   109     0     0   106    28    45   180   200  ... -9999 -9999   \n",
      "2012-01-03     8     0     0   117    72    23   180   170  ... -9999 -9999   \n",
      "2012-01-04   203     0     0   122    56    47   180   190  ... -9999 -9999   \n",
      "2012-01-05    13     0     0    89    28    61   200   220  ... -9999 -9999   \n",
      "\n",
      "            WT02  WT22  WT04  WT13  WT16  WT08  WT18  WT03  \n",
      "DATE                                                        \n",
      "2012-01-01 -9999 -9999 -9999 -9999 -9999 -9999 -9999 -9999  \n",
      "2012-01-02 -9999 -9999 -9999     1     1 -9999 -9999 -9999  \n",
      "2012-01-03 -9999 -9999 -9999 -9999     1 -9999 -9999 -9999  \n",
      "2012-01-04 -9999 -9999 -9999     1     1 -9999 -9999 -9999  \n",
      "2012-01-05 -9999 -9999 -9999 -9999     1 -9999 -9999 -9999  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))\n",
    "print(len(weather))\n",
    "print(counts[:5])\n",
    "print(weather[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc544603",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = counts.resample('d').sum()\n",
    "daily['Total'] = daily.sum(axis=1)\n",
    "daily = daily[['Total']] # remove other columns\n",
    "print(daily[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an indicator about Mon - Sun\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "for i in range(7):\n",
    "    daily[days[i]] = (daily.index.dayofweek == i).astype(float)\n",
    "    \n",
    "print(daily[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1186d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an indicator about holiday\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays('2012', '2016')\n",
    "daily = daily.join(pd.Series(1, index=holidays, name='holiday'))\n",
    "# replace missing data with 0\n",
    "daily['holiday'].fillna(0, inplace=True)\n",
    "\n",
    "print(daily[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function seems crazy. The main goal is to calculate hours of daylight\n",
    "# https://www.esrl.noaa.gov/gmd/grad/solcalc/sunrise.html here is an example...\n",
    "def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
    "    \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
    "    days = (date - pd.datetime(2000, 12, 21)).days\n",
    "    m = (1. - np.tan(np.radians(latitude))\n",
    "         * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
    "    return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
    "\n",
    "daily['daylight_hrs'] = list(map(hours_of_daylight, daily.index))\n",
    "daily[['daylight_hrs']].plot()\n",
    "plt.ylim(8, 17)\n",
    "\n",
    "print(daily[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf9cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of years passed\n",
    "daily['annual'] = (daily.index - daily.index[0]).days / 365."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values\n",
    "daily.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "column_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'holiday',\n",
    "                'daylight_hrs', 'PRCP', 'dry day', 'Temp (C)', 'annual']\n",
    "X = daily[column_names]\n",
    "y = daily['Total']\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "daily['predicted'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperatures are in 1/10 deg C; convert to C\n",
    "weather['TMIN'] /= 10\n",
    "weather['TMAX'] /= 10\n",
    "weather['Temp (C)'] = 0.5 * (weather['TMIN'] + weather['TMAX'])\n",
    "\n",
    "# precip is in 1/10 mm; convert to inches\n",
    "weather['PRCP'] /= 254\n",
    "weather['dry day'] = (weather['PRCP'] == 0).astype(int)\n",
    "\n",
    "daily = daily.join(weather[['PRCP', 'Temp (C)', 'dry day']])\n",
    "# how='left' means calling frameâ€™s index \n",
    "# daily = daily.join(weather[['PRCP', 'Temp (C)', 'dry day']], how='left', lsuffix='_left', rsuffix='_right')\n",
    "\n",
    "daily[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd37e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loop here for each model (Linear, Ridge, Lasso)\n",
    "daily[:5]\n",
    "daily.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c082b10",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'estimator' and 'param_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1d14bf506817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# numpy arange(1, 10, 0.1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'estimator' and 'param_distributions'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# numpy arange(1, 10, 0.1)\n",
    "r = RandomizedSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark\n",
    "# TODO Ridge \n",
    "# ref Linear-Regression/Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kevin\n",
    "# TODO Lasso\n",
    "# ref Linear-Regression/Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matt\n",
    "# K-cross fold validation (k = 10)\n",
    "# ref Evaluation/Model Validation folder "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
